---
title: 'Build a Basic Camera Filter App with SwiftUI'
date: '2023-08-12'
lastmod: '2023-08-12'
tags: ['tutorial', 'camera', 'AV Foundation', 'SwiftUI']
draft: false
summary: ''
layout: PostLayout
---

## Overview

<TOCInline toc={props.toc} exclude="Overview" toHeading={(2, 3)}></TOCInline>

## Setting Up the Project

## Creating the Camera View

Let's start with a basic user interface that will allow us to preview the camera feed and take a photo. We'll start by creating a new SwiftUI view called `CameraView`:

```swift
import SwiftUI

struct CameraView: View {
    var body: some View {
        VStack {
            CameraPreview()
                .aspectRatio(4/3, contentMode: .fit)

            Spacer()

            HStack {
                Spacer()
                Button("Take Photo") {
                    // Implement photo capture logic
                }
                .padding()
            }
        }
    }
}
```

We'll also need to create a `CameraPreview` view that will display the camera feed. We'll use the `UIViewRepresentable` protocol to wrap the `AVCaptureVideoPreviewLayer` class:

```swift
import SwiftUI
import AVFoundation

struct CameraPreview: UIViewRepresentable {
    func makeUIView(context: Context) -> AVCaptureVideoPreviewLayer {
        let previewLayer = AVCaptureVideoPreviewLayer(session: session)
        previewLayer.videoGravity = .resizeAspectFill
        return previewLayer
    }

    func updateUIView(_ uiView: AVCaptureVideoPreviewLayer, context: Context) {
        uiView.session = session
    }

    private let session = AVCaptureSession()
}
```

We'll also need to add the `AVFoundation` framework to our project. We can do this by selecting the project in the Project Navigator, selecting the target, and then selecting the "Build Phases" tab. From there, we can click the "+" button under "Link Binary With Libraries" and select the "AVFoundation.framework" from the list.

## Configuring the Camera

Now that we have a basic user interface, we can start configuring the camera. We'll start by creating a `CameraController` class that will handle the camera configuration logic.

First, let's import the `AVFoundation` framework and create a new `CameraController` class:

```swift
import AVFoundation
import UIKit

class CameraController: ObservableObject {

}
```

Next, let's define the properties that we'll need to configure the camera:

```swift
import AVFoundation
import UIKit

class CameraController: ObservableObject {
    private let captureSession = AVCaptureSession()
    private var videoOutput: AVCaptureVideoDataOutput?
    private var photoOutput: AVCapturePhotoOutput?
    private var previewLayer: AVCaptureVideoPreviewLayer?

    @Published var currentImage: UIImage?

    init() {
        setupCamera()
    }
}
```

Let's break down the purpose behind each of these properties:

**captureSession** - Holds the `AVCaptureSession` instance that we'll use to configure the camera.

**videoOutput** - Holds the `AVCaptureVideoDataOutput` instance that we'll use to capture the live video feed.

**previewLayer** - Holds the `AVCaptureVideoPreviewLayer` instance that we'll use to display the camera feed to the user interface.

**photoOutput** - Holds the `AVCapturePhotoOutput` instance that we'll use to capture photos.

**currentImage** - Allows us to display the captured image to the user interface. Notice that this is a `@Published` property. This is so we can update the UI whenever the image changes.

Lastly, we've created an initializer that will configure the camera when the `CameraController` instance is created, `setupCamera`. Let's implement the `setupCamera()` method:

```swift
private func setupCamera() {
    captureSession.beginConfiguration()

    guard let backCamera = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .back) else {
        print("Unable to access the back camera.")
        return
    }
}
```

In this snippet, we're configuring `setupCamera()`. We start by calling the `beginConfiguration()` method on the `captureSession` property. This allows us to make changes to the session before we start it. The `beginConfiguration()` method is a builtin method of the `AVCaptureSession` class, you can read more about it [here](https://developer.apple.com/documentation/avfoundation/avcapturesession/1385609-beginconfiguration).

We are using the `AVCaptureDevice` class to access the back camera. If successful, we will use the `backCamera` property to configure the input and output for the camera session. Otherwise, an error message will be printed.

```swift
guard let backCamera = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .back) else {
    print("Unable to access the back camera.")
    return
}
```

Next, we have created a do - catch block to handle any errors that may occur when setting up the camera. We'll implement the `do` block in the next section. In the `catch` block, we print the error message to the console.

Lastly, we call the `commitConfiguration()` method on the `captureSession` property. This method commits the configuration changes that we made to the session. You can read more about it [here](https://developer.apple.com/documentation/avfoundation/avcapturesession/1385608-commitconfiguration).

The final `CameraController` class should look something like this:

```swift
import AVFoundation
import UIKit

class CameraController: ObservableObject {
    private let captureSession = AVCaptureSession()
    private var videoOutput: AVCaptureVideoDataOutput?
    private var photoOutput: AVCapturePhotoOutput?
    private var previewLayer: AVCaptureVideoPreviewLayer?

    @Published var currentImage: UIImage?

    init() {
        setupCamera()
    }

    private func setupCamera() {
        captureSession.beginConfiguration()

        guard let backCamera = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .back) else {
            print("Unable to access the back camera.")
            return
        }

        do {
            let input = try AVCaptureDeviceInput(device: backCamera)
            if captureSession.canAddInput(input) {
                captureSession.addInput(input)

                videoOutput = AVCaptureVideoDataOutput()
                videoOutput?.setSampleBufferDelegate(self, queue: DispatchQueue(label: "cameraQueue"))
                if captureSession.canAddOutput(videoOutput!) {
                    captureSession.addOutput(videoOutput!)
                }

                photoOutput = AVCapturePhotoOutput()
                if captureSession.canAddOutput(photoOutput!) {
                    captureSession.addOutput(photoOutput!)
                }

                previewLayer = AVCaptureVideoPreviewLayer(session: captureSession)
                previewLayer?.videoGravity = .resizeAspectFill
            }
        } catch {
            print("Error setting up camera: \(error.localizedDescription)")
        }

        captureSession.commitConfiguration()
    }

    func startSession() {
        if !captureSession.isRunning {
            captureSession.startRunning()
        }
    }

    func stopSession() {
        if captureSession.isRunning {
            captureSession.stopRunning()
        }
    }

    func takePhoto() {
        guard let photoOutput = self.photoOutput else {
            return
        }

        let photoSettings = AVCapturePhotoSettings()
        photoOutput.capturePhoto(with: photoSettings, delegate: self)
    }
}

extension CameraManager: AVCapturePhotoCaptureDelegate, AVCaptureVideoDataOutputSampleBufferDelegate {
    func photoOutput(_ output: AVCapturePhotoOutput, didFinishProcessingPhoto photo: AVCapturePhoto, error: Error?) {
        if let imageData = photo.fileDataRepresentation(), let image = UIImage(data: imageData) {
            currentImage = image
        }
    }

    func captureOutput(_ output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection) {
        // Implement live video feed processing if needed
    }
}
```

## Integrating the Camera with SwiftUI

```swift
struct CameraView: View {
    @StateObject private var cameraManager = CameraManager()

    var body: some View {
        VStack {
            CameraPreview(previewLayer: cameraManager.previewLayer)
                .aspectRatio(4/3, contentMode: .fit)

            Spacer()

            HStack {
                Spacer()
                Button("Take Photo") {
                    cameraManager.takePhoto()
                }
                .padding()
            }
        }
        .onAppear {
            cameraManager.startSession()
        }
        .onDisappear {
            cameraManager.stopSession()
        }
    }
}

struct CameraPreview: UIViewRepresentable {
    let previewLayer: AVCaptureVideoPreviewLayer?

    func makeUIView(context: Context) -> UIView {
        let cameraView = UIView()
        previewLayer?.frame = cameraView.layer.bounds
        cameraView.layer.addSublayer(previewLayer!)
        return cameraView
    }

    func updateUIView(_ uiView: UIView, context: Context) {
        previewLayer?.frame = uiView.layer.bounds
    }
}
```

## Applying Filters to the Camera Feed

```swift
import CoreImage

extension CameraManager {
    func filterImage(_ image: UIImage, withFilter filterName: String) -> UIImage? {
        guard let filter = CIFilter(name: filterName),
              let inputImage = CIImage(image: image) else {
            return nil
        }

        filter.setValue(inputImage, forKey: kCIInputImageKey)

        if let outputImage = filter.outputImage,
           let cgImage = CIContext().createCGImage(outputImage, from: outputImage.extent) {
            return UIImage(cgImage: cgImage)
        }

        return nil
    }
}
```

## Display Filtered Images

```swift
struct ContentView: View {
    @StateObject private var cameraManager = CameraManager()
    @State private var capturedImage: UIImage?

    var body: some View {
        VStack {
            if let image = capturedImage {
                Image(uiImage: image)
                    .resizable()
                    .aspectRatio(contentMode: .fit)
            } else {
                CameraPreview(previewLayer: cameraManager.previewLayer)
                    .aspectRatio(4/3, contentMode: .fit)
            }
        }
        .onAppear {
            cameraManager.startSession()
        }
        .onDisappear {
            cameraManager.stopSession()
        }

        HStack {
            Spacer()
            Button("Take Photo") {
                cameraManager.takePhoto()
            }
            .padding()
        }
    }
}
```
